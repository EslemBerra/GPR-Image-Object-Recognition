# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1e8QAw2rHZGnR5GqPgAAb7I6ILbRVWBdV
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install Pillow
!pip install numpy
!pip install ultralytics
!pip install opencv-python
!pip install tensorflow

!pip install keras
!pip install scikit-learn
!pip install matplotlib
!pip install pandas

import os
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
import cv2

# Resimleri yükleme ve etiketleme
def load_images_from_folder(folder, label):
    images = []
    labels = []
    for filename in os.listdir(folder):
        img = cv2.imread(os.path.join(folder, filename))
        if img is not None:
            img = cv2.resize(img, (224, 224))  # ResNet50 için boyutlandırma
            images.append(img)
            labels.append(label)
    return images, labels

# Veri setini yükleyelim
train_folder_images = '/content/drive/MyDrive/GPR Recognition/dataset/train/images'
train_folder_labels = '/content/drive/MyDrive/GPR Recognition/dataset/train/labels'

test_folder_images = '/content/drive/MyDrive/GPR Recognition/dataset/test/images'
test_folder_labels = '/content/drive/MyDrive/GPR Recognition/dataset/test/labels'

# Stell-rib ve Hyperbola etiketleri
stell_rib_images, stell_rib_labels = load_images_from_folder(train_folder_images, 0)  # 0: Stell-rib
hyperbola_images, hyperbola_labels = load_images_from_folder(test_folder_images, 1)  # 1: Hyperbola

# Veriyi birleştir
train_images = np.array(stell_rib_images + hyperbola_images)
train_labels = np.array(stell_rib_labels + hyperbola_labels)

# Veriyi test ve train olarak ayıralım
X_train, X_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.2, random_state=42)

from ultralytics import YOLO
# YOLOv11 Modeli ile Eğitim
yaml_file = '/content/drive/MyDrive/GPR Recognition/dataset/data.yaml'
model = YOLO('yolo11n.pt')
model.train(
    data=yaml_file,
    epochs=50,
    imgsz=640,
    batch=32,
    name='gpr_detection'
)

# Test veri seti üzerinde tahmin
output_dir = '/content/runs/detect/predict'
os.makedirs(output_dir, exist_ok=True)
test_results = model.predict(
    source=test_folder_images,
    conf=0.25,
    save=True
)

# Bounding Box ve Etiket Görselleştirme
counter = 0  # Tahmin edilen görüntüler için sayaç
for result in test_results:
    img = result.orig_img  # Orijinal görüntü
    for box, cls in zip(result.boxes.xyxy, result.boxes.cls):  # Box ve sınıf bilgilerini birlikte döngüye alın
        x1, y1, x2, y2 = map(int, box.tolist())  # Tensor'dan listeye dönüştürüp int yapın
        class_id = int(cls)  # Sınıf ID'sini alın
        label = model.names[class_id]  # Etiketi alın
        # Görüntüye bounding box ve etiket ekleyin
        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 0), 2)
        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)
    # Çıktı dosyasını kaydedin
    output_path = os.path.join(output_dir, f"result_{counter}.jpg")
    cv2.imwrite(output_path, img)
    counter += 1  # Sayaç artır

# ResNet50 modelini yüklüyoruz
base_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Modeli donmuş (frozen) katmanlarla başlatıyoruz
base_model.trainable = False

# Modeli tamamlıyoruz
classification_model = tf.keras.Sequential([
    base_model,
    tf.keras.layers.GlobalAveragePooling2D(),
    tf.keras.layers.Dense(1024, activation='relu'),
    tf.keras.layers.Dropout(0.3),  # Dropout ekleyerek overfitting'i azaltıyoruz
    tf.keras.layers.Dense(2, activation='softmax')  # 2 sınıf: Stell-rib ve Hyperbola
])

# Modeli derleyelim
lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
    initial_learning_rate=0.001,
    decay_steps=1000,
    decay_rate=0.9
)
optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)
classification_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])

# Eğitim sırasında veri artırma (data augmentation) yapıyoruz
datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)

# Eğitim verisini ve doğrulama verisini hazırlıyoruz
train_gen = datagen.flow(X_train, y_train, batch_size=32)
val_gen = ImageDataGenerator(rescale=1./255).flow(X_val, y_val, batch_size=32)

# Modeli eğitiyoruz
history = classification_model.fit(train_gen, epochs=50, validation_data=val_gen)

# Doğruluk grafiği
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label='val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0, 1])
plt.legend(loc='lower right')
plt.show()

# Test verisi ile tahmin yapalım
y_pred = classification_model.predict(X_val)
y_pred_classes = np.argmax(y_pred, axis=1)

# Confusion Matrix hesaplayalım
cm = confusion_matrix(y_val, y_pred_classes)

# Confusion Matrix görselleştirelim
plt.figure(figsize=(7,7))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Stell-rib', 'Hyperbola'], yticklabels=['Stell-rib', 'Hyperbola'])
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.show()